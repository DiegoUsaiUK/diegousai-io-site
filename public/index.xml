<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-UK</language>
    <lastBuildDate>Mon, 20 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 3 of 3 - Optimise Profit With the Expected Value Framework</title>
      <link>/2020/04/propensity-modelling-3-of-3/</link>
      <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/propensity-modelling-3-of-3/</guid>
      <description>In this day and age, a business that leverages data to understand the drivers of its customers&amp;rsquo; behaviour has a true competitive advantage. Organisations can dramatically improve their performance in the market by analysing customer level data in an effective way and focus their efforts towards those that are more likely to engage.
One trialled and tested approach to tease out this type of insight is Propensity Modelling, which combines information such as a customers’ demographics (age, race, religion, gender, family size, ethnicity, income, education level), psycho-graphic (social class, lifestyle and personality characteristics), engagement (emails opened, emails clicked, searches on mobile app, webpage dwell time, etc.</description>
    </item>
    
    <item>
      <title>Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 2 of 3 - Estimate Several Models and Compare Their Performance Using a Model-agnostic Methodology</title>
      <link>/2020/03/propensity-modelling-2-of-3/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/03/propensity-modelling-2-of-3/</guid>
      <description>In this day and age, a business that leverages data to understand the drivers of its customers&amp;rsquo; behaviour has a true competitive advantage. Organisations can dramatically improve their performance in the market by analysing customer level data in an effective way and focus their efforts towards those that are more likely to engage.
One trialled and tested approach to tease out this type of insight is Propensity Modelling, which combines information such as a customers’ demographics (age, race, religion, gender, family size, ethnicity, income, education level), psycho-graphic (social class, lifestyle and personality characteristics), engagement (emails opened, emails clicked, searches on mobile app, webpage dwell time, etc.</description>
    </item>
    
    <item>
      <title>Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 1 of 3 - Data Preparation and Exploratory Data Analysis</title>
      <link>/2020/02/propensity-modelling-1-of-3/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/propensity-modelling-1-of-3/</guid>
      <description>In this day and age, a business that leverages data to understand the drivers of its customers&amp;rsquo; behaviour has a true competitive advantage. Organisations can dramatically improve their performance in the market by analysing customer level data in an effective way and focus their efforts towards those that are more likely to engage.
One trialled and tested approach to tease out this type of insight is Propensity Modelling, which combines information such as a customers’ demographics (age, race, religion, gender, family size, ethnicity, income, education level), psycho-graphic (social class, lifestyle and personality characteristics), engagement (emails opened, emails clicked, searches on mobile app, webpage dwell time, etc.</description>
    </item>
    
    <item>
      <title>Time Series Machine Learning Analysis and Demand Forecasting with H2O &amp; TSstudio</title>
      <link>/2019/12/time-series-machine-learning-analysis-and-demand-forecasting/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/time-series-machine-learning-analysis-and-demand-forecasting/</guid>
      <description>Traditional approaches to time series analysis and forecasting, like Linear Regression, Holt-Winters Exponential Smoothing, ARMA/ARIMA/SARIMA and ARCH/GARCH, have been well-established for decades and find applications in fields as varied as business and finance (e.g. predict stock prices and analyse trends in financial markets), the energy sector (e.g. forecast electricity consumption) and academia (e.g. measure socio-political phenomena).
In more recent times, the popularisation and wider availability of open source frameworks like Keras, TensorFlow and scikit-learn helped machine learning approaches like Random Forest, Extreme Gradient Boosting, Time Delay Neural Network and Recurrent Neural Network to gain momentum in time series applications.</description>
    </item>
    
    <item>
      <title>Build Your Website with Hugo and blogdown - How I used RStudio, GitHub and Netlify to create and deploy my own webpage</title>
      <link>/2019/10/build-your-website-with-hugo-and-blogdown/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/10/build-your-website-with-hugo-and-blogdown/</guid>
      <description>This year has been rather rewarding for me! After completing some of the excellent Business Science University courses, I have worked on a number of Customer Analytics &amp;amp; Business Intelligence projects and summarised them into technical articles that I published on Medium&amp;rsquo;s Towards Data Science. This opened up an entirely new world to me and generated many new connections within the analytics and data science community the world over!</description>
    </item>
    
    <item>
      <title>Diego Usai</title>
      <link>/page/about/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/page/about/</guid>
      <description>A competent Analytics Professional, Consultant and Data Manager, with expertise in Project Management, Team Leadership and Stakeholder Management and an insatiable curiosity about how to use data to inform business decisions.
I have extensive experience of managing and delivering end-to-end Customer Insight, Business Intelligence and Marketing Analytics projects, from engaging with business stakeholders and scoping out requirements through to formulating recommendations and communicating insight in a commercial and compelling manner. I have also been responsible for building, leading and coaching an analytics team to deliver ad-hoc modelling as well as more holistic analytic projects.</description>
    </item>
    
    <item>
      <title>ResouRces</title>
      <link>/page/links/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/page/links/</guid>
      <description> Links to some of my favourite blogs/books/sites Blogs  Storybench ~ Digital storytelling &amp;amp; Data Journalism from the Northeastern University&amp;rsquo;s school of journalism Towards Data Science ~ A platform to exchange ideas and to expand your understanding of Data Science Business Science ~ Matt Dancho&amp;rsquo;s blog focused on all things Business Science KDnuggets ~ The influential discussion and learning website for Business Analytics, Data Mining and Data Science  Newsletters  The Analytics Dispatch ~ Mode weekly brief about data, data science, and analytics The Week in Data ~ Open Data Institute weekly digest to keep your finger on the pulse of the world of data Data Science Weekly ~ A weekly summary featuring curated news, articles and jobs related to Data Science Data Elixir ~ A weekly email newsletter that keeps you on top of the tools and trends in Data Science with top picks from around the web Data Is Plural ~ Jeremy Singer-Vine weekly compendium of useful/curious datasets — both serious and lighthearted  Books  An Introduction to Statistical Learning ~ This books provides an introduction to statistical learning methods and contains a number of R labs with detailed explanations on how to implement the various methods in real life settings Hands-On Time Series Analysis with R ~ Explore data, identify patterns, and build efficient forecasting models using traditional time series models and machine learning algorithms Interpretable Machine Learning ~ This book discusses how to explain or present in understandable terms the output of Black Box Machin Learning models, tackling when interpretability is important and what different types of explanations there are R for Data Science ~ A modern version of R for data science, from basic data management (loading, exploring and combining) to more advanced topics such as functional programming, nested tibbles and interactive reports R for Marketing Research and Analytics ~ A complete introduction to R for marketing research, with emphasis on data visualization, model assessment, and development of statistical intuition  Volunteering  School of Data ~ A global network of data literacy practitioners (organisations and individuals alike) committed to advancing data literacy in civil society SoGooD²ata ~ A friendly Spanish NGO which aims at solving social issues applying data science techniques  </description>
    </item>
    
    <item>
      <title>Loading, Merging and Joining Datasets</title>
      <link>/2019/09/loading-merging-and-joining-datasets/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/loading-merging-and-joining-datasets/</guid>
      <description>This is the minimal coding necessary to assemble various data feeds and sort out the likes of variables naming &amp;amp; new features creation plus some general housekeeping tasks. It includes general housekeeping tasks like sorting variables names, creating essential features and sorting out variables order
I will continue to add to this code should the need arise for other features to be created.
The Dataset library(tidyverse) library(lubridate) library(readr)  The dataset I&amp;rsquo;m using here accompanies a Redbooks publication called Building 360-Degree Information Applications which is available as a free PDF download.</description>
    </item>
    
    <item>
      <title>Steps and considerations to run a successful segmentation with K-means, Principal Components Analysis and Bootstrap Evaluation</title>
      <link>/2019/09/steps-and-considerations-to-run-a-successful-segmentation/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/steps-and-considerations-to-run-a-successful-segmentation/</guid>
      <description>Clustering is one of my favourite analytic methods: it resonates well with clients as I&amp;rsquo;ve found from my consulting experience, and is a relatively straightforward concept to explain non technical audiences.
Earlier this year I&amp;rsquo;ve used the popular K-Means clustering algorithm to segment customers based on their response to a series of marketing campaigns. For that post I&amp;rsquo;ve deliberately used a basic dataset to show that it is not only a relatively easy analysis to carry out but can also help unearthing interesting patterns of behaviour in your customer base even when using few customer attributes.</description>
    </item>
    
    <item>
      <title>Modelling with Tidymodels and Parsnip - A Tidy Approach to a Classification Problem</title>
      <link>/2019/06/modelling-with-tidymodels-and-parsnip/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/modelling-with-tidymodels-and-parsnip/</guid>
      <description>Recently I have completed the online course Business Analysis With R focused on applied data and business science with R, which introduced me to a couple of new modelling concepts and approaches. One that especially captured my attention is parsnip and its attempt to implement a unified modelling and analysis interface (similar to python&amp;rsquo;s scikit-learn) to seamlessly access several modelling platforms in R.
parsnip is the brainchild of RStudio&amp;rsquo;s Max Khun (of caret fame) and Davis Vaughan and forms part of tidymodels, a growing ensemble of tools to explore and iterate modelling tasks that shares a common philosophy (and a few libraries) with the tidyverse.</description>
    </item>
    
    <item>
      <title>A gentle Introduction to Customer Segmentation - Using K-Means Clustering to Understand Marketing Response</title>
      <link>/2019/05/a-gentle-introduction-to-customer-segmentation/</link>
      <pubDate>Sat, 25 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/a-gentle-introduction-to-customer-segmentation/</guid>
      <description>Market segmentation refers to the process of dividing a consumer market of existing and/or potential customers into groups (or segments) based on shared attributes, interests, and behaviours.
For this mini-project I will use the popular K-Means clustering algorithm to segment customers based on their response to a series of marketing campaigns. The basic concept is that consumers who share common traits would respond to marketing communication in a similar way so that companies can reach out for each group in a relevant and effective way.</description>
    </item>
    
    <item>
      <title>Market Basket Analysis - Part 3 of 3 - A Shiny Product Recommender with Improved Collaborative Filtering</title>
      <link>/2019/04/market-basket-analysis-part-3-of-3/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/market-basket-analysis-part-3-of-3/</guid>
      <description>My objective for this piece of work is to carry out a Market Basket Analysis as an end-to-end data science project. I have split the output into three parts, of which this is the THIRD and last, that I have organised as follows:
 In the first chapter, I will source, explore and format a complex dataset suitable for modelling with recommendation algorithms.
 For the second part, I will apply various machine learning algorithms for Product Recommendation and select the best performing model.</description>
    </item>
    
    <item>
      <title>Market Basket Analysis - Part 2 of 3 - Market Basket Analysis with recommenderlab</title>
      <link>/2019/03/market-basket-analysis-part-2-of-3/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/market-basket-analysis-part-2-of-3/</guid>
      <description>My objective for this piece of work is to carry out a Market Basket Analysis as an end-to-end data science project. I have split the output into three parts, of which this is the SECOND, that I have organised as follows:
 In the first chapter, I will source, explore and format a complex dataset suitable for modelling with recommendation algorithms.
 For the second part, I will apply various machine learning algorithms for Product Recommendation and select the best performing model.</description>
    </item>
    
    <item>
      <title>Market Basket Analysis - Part 1 of 3 - Data Preparation and Exploratory Data Analysis</title>
      <link>/2019/03/market-basket-analysis-part-1-of-3/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/market-basket-analysis-part-1-of-3/</guid>
      <description>My objective for this piece of work is to carry out a Market Basket Analysis as an end-to-end data science project. I have split the output into three parts, of which this is the FIRST, that I have organised as follows:
 In the first chapter, I will source, explore and format a complex dataset suitable for modelling with recommendation algorithms.
 For the second part, I will apply various machine learning algorithms for Product Recommendation and select the best performing model.</description>
    </item>
    
  </channel>
</rss>