<!DOCTYPE html>
<html lang="en-UK" />
<head>
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

    <title>Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 3 of 3 - Optimise Profit With the Expected Value Framework &middot; </title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="/favicon.ico" />
    <link rel="canonical" href="/2020/04/propensity-modelling-3-of-3/" />

     <meta name="description" content="In this day and age, a business that leverages data to understand the drivers of its customers&amp;rsquo; behaviour has a true competitive advantage. Organisations " /> 

     
    
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image" content="/img/david-sury-X6M3svSX8dc-unsplash.jpg"/>
    
 
    <meta name="twitter:title" content="Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 3 of 3 - Optimise Profit With the Expected Value Framework"/>
    <meta name="twitter:description" content="In this day and age, a business that leverages data to understand the drivers of its customers&amp;rsquo; behaviour has a true competitive advantage. Organisations "/>
    <meta name="twitter:url" content="/2020/04/propensity-modelling-3-of-3/" />
    <meta name="twitter:site" content="@"/>

    <meta property="og:site_name" content="" />
    <meta property="og:title" content="Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 3 of 3 - Optimise Profit With the Expected Value Framework &middot; Lifelong Learning" />
    <meta property="og:url" content="/2020/04/propensity-modelling-3-of-3/" />
    

    <meta property="og:type" content="article" />
    <meta property="og:description" content="In this day and age, a business that leverages data to understand the drivers of its customers&amp;rsquo; behaviour has a true competitive advantage. Organisations " />

    <meta property="article:published_time" content="2020-04-20T00:00:00Z" />
    <meta property="article:tag" content="Propensity Modelling" /><meta property="article:tag" content="Machine Learning" /><meta property="article:tag" content="Optimisation" />

    <meta property="og:image" content="/img/david-sury-X6M3svSX8dc-unsplash.jpg"/>


    <meta name="generator" content="Hugo 0.58.3" />

    <!-- Stylesheets -->
    <link rel="stylesheet" type="text/css" href="/built/screen.css" /> 
    <link rel="stylesheet" type="text/css" href="/css/casper-two.css" /> 
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" />
     <link rel="stylesheet" href="/css/override.css" /> 

     

</head>


<body class="post-template">
  <div class="site-wrapper"> 

<header class="site-header outer">
  <div class="inner">
    <nav class="site-nav">
      <div class="site-nav-left">

        <ul class="nav" role="menu">
        
        
        
            <li class="" role="menuitem">
              <a href="/">Home</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/categories/articles/">Articles</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/categories/multi-post-studies/">projects</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/tags/">Tags</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/page/links/">Readings</a>
            </li>
        
            <li class="" role="menuitem">
              <a href="/page/about/">About</a>
            </li>
        
      </ul></div>

      <div class="site-nav-right">
        <div class="social-links">
                    

                    

                    <a class="social-link" href="https://github.com/DiegoUsaiUK" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>

                    <a class="social-link" href="https://www.linkedin.com/in/diegousaiuk" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 50 512 512"><path d="M150.65,100.682c0,27.992-22.508,50.683-50.273,50.683c-27.765,0-50.273-22.691-50.273-50.683 C50.104,72.691,72.612,50,100.377,50C128.143,50,150.65,72.691,150.65,100.682z M143.294,187.333H58.277V462h85.017V187.333z M279.195,187.333h-81.541V462h81.541c0,0,0-101.877,0-144.181c0-38.624,17.779-61.615,51.807-61.615 c31.268,0,46.289,22.071,46.289,61.615c0,39.545,0,144.181,0,144.181h84.605c0,0,0-100.344,0-173.915 s-41.689-109.131-99.934-109.131s-82.768,45.369-82.768,45.369V187.333z" /></svg></a>

                    <a class="social-link" href="https://medium.com/@diegousaiuk" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 195 195"><path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z"/></svg></a>
        </div>  
            
      </div>

    </nav>  

  </div>
</header>

<main id="site-main" class="site-main outer" role="main">
  <div class="inner">
    
      <article class="post-full post"> 
    <header class="post-full-header">
        <section class="post-full-meta">
            <time class="post-full-meta-date" datetime="2020-04-20">20 April 2020</time>
                <span class="date-divider">/</span> <a href="/tags/propensity-modelling/">#Propensity Modelling</a>&nbsp;<a href="/tags/machine-learning/">#Machine Learning</a>&nbsp;
        </section>
        <h1 class="post-full-title">Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 3 of 3 - Optimise Profit With the Expected Value Framework</h1>
    </header>
    
    <figure class="post-full-image" style="background-image: url(/img/david-sury-X6M3svSX8dc-unsplash.jpg)">
    </figure>

    <section class="post-full-content">
        <div class="kg-card-markdown">
        

<p>In this day and age, a business that leverages data to understand the drivers of its customers&rsquo; behaviour has a true competitive advantage. Organisations can dramatically improve their performance in the market by analysing customer level data in an effective way and focus their efforts towards those that are more likely to engage.</p>

<p>One trialled and tested approach to tease out this type of insight is <a href="https://en.wikipedia.org/wiki/Predictive_modelling"><strong>Propensity Modelling</strong></a>, which combines information such as a <strong>customers’ demographics</strong> (age, race, religion, gender, family size, ethnicity, income, education level), <strong>psycho-graphic</strong> (social class, lifestyle and personality characteristics), <strong>engagement</strong> (emails opened, emails clicked, searches on mobile app, webpage dwell time, etc.), <strong>user experience</strong> (customer service phone and email wait times, number of refunds, average shipping times), and <strong>user behaviour</strong> (purchase value on different time-scales, number of days since most recent purchase, time between offer and conversion, etc.) to estimate the likelihood of a certain customer profile to performing a certain type of behaviour (e.g. the purchase of a product).</p>

<p>Once you understand the probability of a certain customer to interact with your brand, buy a product or a sign up for a service, you can use this information to create scenarios, be it minimising <strong>marketing expenditure</strong>, maximising <strong>acquisition targets</strong>, and optimise <strong>email send frequency</strong> or <strong>depth of discount</strong>.</p>

<h2 id="project-structure">Project Structure</h2>

<p>In this project I&rsquo;m analysing the results of a bank <strong>direct marketing campaign</strong> to sell term deposits in order to identify what type of customer is more likely to respond. The marketing campaigns were based on phone calls and more than one contact to the same client was required at times.</p>

<p>First, I am going to carry out an <strong>extensive data exploration</strong> and use the results and insights to prepare the data for analysis.</p>

<p>Then, I&rsquo;m <strong>estimating a number of models</strong> and assess their performance and fit to the data using a <strong>model-agnostic methodology</strong> that enables to <strong>compare traditional &ldquo;glass-box&rdquo; models and &ldquo;black-box&rdquo; models</strong>.</p>

<p>Last, I&rsquo;ll fit <strong>one final model</strong> that combines findings from the exploratory analysis and insight from models&rsquo; selection and use it to <strong>run a basic profit optimisation</strong>.</p>

<h2 id="optimising-for-expected-profit">Optimising for expected profit</h2>

<pre><code class="language-r">library(tidyverse)
library(skimr)
library(h2o)
library(knitr)
library(tictoc)
</code></pre>

<p>Now that I have my final model, the last piece of the puzzle is the final “So what?” question that puts all into perspective. The estimate for the probability of a customer to sign up for a term deposit can be used to create a number of optimised scenarios, ranging from minimising your <strong>marketing expenditure</strong>, maximising your <strong>overall acquisitions</strong>, to driving a certain number of <strong>cross-sell opportunities</strong>.</p>

<p>Before I can do that, there are a couple of <strong>housekeeping tasks</strong>  needed to &ldquo;set up the work scene&rdquo; and a couple of important concepts to introduce:</p>

<ul>
<li><p>the threshold and the F1 score</p></li>

<li><p>precision and recall</p></li>
</ul>

<h3 id="a-few-housekeeping-tasks">A few housekeeping tasks</h3>

<p>I load the clensed data saved at the end of the exploratory analysis</p>

<pre><code class="language-r"># Loading clensed data
data_final &lt;- readRDS(file = &quot;../01_data/data_final.rds&quot;)
</code></pre>

<p>From that, I create a randomised training and validation set with <code>rsample</code> and save them as <code>train_tbl</code> and <code>test_tbl</code>.</p>

<pre><code class="language-r">set.seed(seed = 1975) 

train_test_split &lt;-
  rsample::initial_split(
    data = data_final,     
    prop = 0.80   
  ) 

train_tbl &lt;- train_test_split %&gt;% rsample::training() 
test_tbl  &lt;- train_test_split %&gt;% rsample::testing() 
</code></pre>

<p>I also need to start a <strong>h2o cluster</strong>, turn off the progress bar and load the final random forest model</p>

<pre><code class="language-r"># initialize h2o session and switch off progress bar
h2o.no_progress() 
h2o.init(max_mem_size = &quot;16G&quot;)

## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     C:\Users\LENOVO\AppData\Local\Temp\RtmpkRk5j9/h2o_LENOVO_started_from_r.out
##     C:\Users\LENOVO\AppData\Local\Temp\RtmpkRk5j9/h2o_LENOVO_started_from_r.err
## 
## 
## Starting H2O JVM and connecting:  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         3 seconds 172 milliseconds 
##     H2O cluster timezone:       Europe/Berlin 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.28.0.4 
##     H2O cluster version age:    2 months and 4 days  
##     H2O cluster name:           H2O_started_from_R_LENOVO_frm928 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   14.21 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4 
##     R Version:                  R version 3.6.3 (2020-02-29)
</code></pre>

<pre><code class="language-r">drf_final &lt;- h2o.loadModel(path = &quot;../03_models/drf_grid_final_model_1&quot;)
</code></pre>

<h3 id="the-threshold-and-the-f1-score">The threshold and the F1 score</h3>

<p>The question the model is trying to answer is &ldquo; <em>Has this customer signed up for a term deposit following a direct marketing campaign?</em> &ldquo; and the cut-off (a.k.a. the threshold) is the value that divides the predictions into <code>Yes</code> and  <code>No</code>.</p>

<p>To illustrate the point, I first calculate some predictions by passing the <code>test_tbl</code> data set to the <code>h2o.performance</code> function.</p>

<pre><code class="language-r">perf_drf_final &lt;- h2o.performance(drf_final, newdata = test_tbl %&gt;% as.h2o()) 

perf_drf_final@metrics$max_criteria_and_metric_scores

## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.189521    0.508408 216
## 2                       max f2  0.108236    0.560213 263
## 3                 max f0point5  0.342855    0.507884 143
## 4                 max accuracy  0.483760    0.903848  87
## 5                max precision  0.770798    0.854167  22
## 6                   max recall  0.006315    1.000000 399
## 7              max specificity  0.930294    0.999864   0
## 8             max absolute_mcc  0.189521    0.444547 216
## 9   max min_per_class_accuracy  0.071639    0.721231 300
## 10 max mean_per_class_accuracy  0.108236    0.755047 263
## 11                     max tns  0.930294 7342.000000   0
## 12                     max fns  0.930294  894.000000   0
## 13                     max fps  0.006315 7343.000000 399
## 14                     max tps  0.006315  894.000000 399
## 15                     max tnr  0.930294    0.999864   0
## 16                     max fnr  0.930294    1.000000   0
## 17                     max fpr  0.006315    1.000000 399
## 18                     max tpr  0.006315    1.000000 399
</code></pre>

<p>Like many other machine learning modelling platforms, <strong>h2o</strong> uses the threshold value associated with the maximum <a href="https://en.wikipedia.org/wiki/F1_score">F1 score</a>, which is nothing but a weighted average between precision and recall. In this case the threshold @ Max F1 is <strong>0.190</strong>.</p>

<p>Now, I use the <code>h2o.predict</code> function to make predictions using the test set. The prediction output comes with three columns: the actual model predictions (<code>predict</code>), and the probabilities associated with that prediction (<code>p0</code>, and <code>p1</code>, corresponding to <code>No</code> and <code>Yes</code> respectively). As you can see, the <code>p1</code> probability associated with the current cut-off is around <strong>0.0646</strong>.</p>

<pre><code class="language-r">drf_predict &lt;- h2o.predict(drf_final, newdata = test_tbl %&gt;% as.h2o())

# I converte to a tibble for ease of use
as_tibble(drf_predict) %&gt;%
  arrange(p0) %&gt;% 
  slice(3088:3093) %&gt;%
  kable()
</code></pre>

<table>
<thead>
<tr>
<th align="left">predict</th>
<th align="left">p0</th>
<th align="left">p1</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">1</td>
<td align="left">0.9352865</td>
<td align="left">0.0647135</td>
</tr>

<tr>
<td align="left">1</td>
<td align="left">0.9352865</td>
<td align="left">0.0647135</td>
</tr>

<tr>
<td align="left">1</td>
<td align="left">0.9352865</td>
<td align="left">0.0647135</td>
</tr>

<tr>
<td align="left">0</td>
<td align="left">0.9354453</td>
<td align="left">0.0645547</td>
</tr>

<tr>
<td align="left">0</td>
<td align="left">0.9354453</td>
<td align="left">0.0645547</td>
</tr>

<tr>
<td align="left">0</td>
<td align="left">0.9354453</td>
<td align="left">0.0645547</td>
</tr>
</tbody>
</table>

<p>However, the <em>F1 score</em> is only one way to identify the cut-off. Depending on our goal, we could also decide to use a threshold that, for instance, maximises precision or recall. In a commercial setting, the pre-selected threshold @ Max F1 may not necessarily be the optimal choice: enter <strong>Precision and Recall</strong>!</p>

<h3 id="precision-and-recall">Precision and Recall</h3>

<p><strong>Precision</strong> shows how sensitive models are to False Positives (i.e. predicting a customer is <em>subscribing</em> when he-she is actually NOT) whereas <strong>Recall</strong> looks at how sensitive models are to False Negatives (i.e. forecasting that a customer is <em>NOT subscribing</em> whilst he-she is in fact going to do so).</p>

<p>These metrics are <strong>very relevant in a business context</strong> because organisations are particularly interested in accurately predicting which customers are truly likely to <code>subscribe</code> <strong>(high precision)</strong> so that they can target them with advertising strategies and other incentives. At the same time they want to minimise efforts towards customers incorrectly classified as <code>subscribing</code> <strong>(high recall)</strong> who are instead unlikely to sign up.</p>

<p>However, as you can see from the chart below, when precision gets higher, recall gets lower and vice versa. This is often referred to as the <strong>Precision-Recall tradeoff</strong>.</p>

<pre><code class="language-r">perf_drf_final %&gt;%
    h2o.metric() %&gt;%
    as_tibble() %&gt;%
    ggplot(aes(x = threshold)) +
    geom_line(aes(y = precision), colour = &quot;darkblue&quot;, size = 1) +
    geom_line(aes(y = recall), colour = &quot;red&quot;, size = 1) +
    geom_vline(xintercept = h2o.find_threshold_by_max_metric(perf_drf_final, &quot;f1&quot;)) +
    theme_minimal() +
    labs(title = 'Precision and Recall with Cut-off @ Max F1',
         subtitle = 'Distributed Random Forest Model',
         x = 'With threshold @ Max F1, probability above 0.0646 predicts subscribed = &quot;Yes&quot;',
         y = 'Precision and Recall Values'
         ) +
    theme(plot.title = element_text(hjust = 0.4),
          plot.subtitle = element_text(hjust = 0.4)) +
  
  # p &lt; 0.0646
    annotate(&quot;text&quot;, x = 0.065, y = 0.50, size = 3, colour = &quot;darkgreen&quot;,
             label = 'p1 &lt; 0.0646 &quot;No&quot;\nNot Subscribed') +
    
  # p=0.0646
    geom_vline(xintercept = 0.190, size = 0.8, colour = &quot;orange&quot;) +
    annotate(&quot;text&quot;, x = 0.19, y = 0.80, size = 3, colour = &quot;darkblue&quot;,
             label = 'p1 = 0.0646 \nCurrent Cut-off \n@ Max F1') +
    
  # p&gt; 0.0646
    annotate(&quot;text&quot;, x = 0.5, y = 0.50, size = 3, colour = &quot;purple&quot;,
             label = 'p1 &gt; 0.0646 &quot;Yes&quot;\n Subscribed') 
</code></pre>

<p><img src="/img/2020-04-20-propensity-modelling-3-of-3-optimise-profit-with-the-expected-value-framework/unnamed-chunk-6-1.png" alt="" width="100%" height="100%"/></p>

<p>To fully comprehend this dynamic and its implications, let&rsquo;s start with taking a look at the <strong>cut-off zero</strong> and <strong>cut-off one</strong> points and then see what happens when you start moving the threshold between the two positions:</p>

<ul>
<li><p>At <strong>threshold zero</strong> ( <em>lowest precision, highest recall</em>) the model classifies every customer as <code>subscribed = Yes</code>. In such scenario, you would <strong>contact every single customers</strong> with direct marketing activity but waste precious resourses by also including those less likely to subcsribe. Clearly this is not an optimal strategy as you&rsquo;d incur in a higher overall acquisition cost.</p></li>

<li><p>Conversely, at <strong>threshold one</strong> ( <em>highest precision, lowest recall</em>) the model tells you that nobody is likely to subscribe so you should <strong>contact no one</strong>. This would save you tons of money in marketing cost but you&rsquo;d be missing out on the additional revenue from those customers who would&rsquo;ve subscribed, had they been notified about the term deposit through direct marketing. Once again, not an optimal strategy.</p></li>
</ul>

<p>With this in mind, when moving to a higher threshold the model becomes more &ldquo;choosy&rdquo; on who it classifies as <code>subscribed = Yes</code>. As a consequence, you become more conservative on who to contact ( <strong>higher precision</strong>) and reduce your acquisition cost, but at the same time you increase your chance of not reaching prospective subscribes ( <strong>lower recall</strong>), missing out on potential revenue.</p>

<p>The key question here is <strong>where do you stop?</strong> Is there a &ldquo;sweet spot&rdquo; and if so, how do you find it? Well, that will depend entirely on the goal you want to achieve. In the next section I&rsquo;ll be running a mini-optimisation with the goal to <strong>maximise profit</strong>.</p>

<h2 id="finding-the-optimal-threshold">Finding the optimal threshold</h2>

<p>For this mini-optimisation I&rsquo;m implementing a <strong>simple profit maximisation</strong> based on generic costs connected to acquiring a new customer and benefits derived from said acquisition. This can be evolved to include more complex scenarios but it would be outside the scope of this exercise.</p>

<p>To understand which cut-off value is optimal to use we need to simulate the cost-benefit associated with each threshold point. This is a concept derived from the <strong>Expected Value Framework</strong> as seen on <a href="https://www.goodreads.com/book/show/17912916-data-science-for-business"><em>Data Science for Business</em></a></p>

<p>To do so I need 2 things:</p>

<ul>
<li><p><strong>Expected Rates for each threshold</strong> - These can be retrieved from the confusion matrix</p></li>

<li><p><strong>Cost/Benefit for each customer</strong> - I will need to simulate these based on assumptions</p></li>
</ul>

<h3 id="expected-rates">Expected rates</h3>

<p>Expected rates can be conveniently retrieved for all cut-off points using <code>h2o.metric</code>.</p>

<pre><code class="language-r"># Get expected rates by cutoff
expected_rates &lt;- h2o.metric(perf_drf_final) %&gt;%
    as.tibble() %&gt;%
    select(threshold, tpr, fpr, fnr, tnr)

expected_rates

## # A tibble: 400 x 5
##    threshold     tpr      fpr   fnr   tnr
##        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     0.930 0       0.000136 1     1.00 
##  2     0.919 0.00112 0.000136 0.999 1.00 
##  3     0.893 0.00112 0.000272 0.999 1.00 
##  4     0.882 0.00224 0.000545 0.998 0.999
##  5     0.879 0.00336 0.000545 0.997 0.999
##  6     0.876 0.00671 0.000545 0.993 0.999
##  7     0.873 0.00783 0.000545 0.992 0.999
##  8     0.867 0.0123  0.000545 0.988 0.999
##  9     0.857 0.0145  0.000545 0.985 0.999
## 10     0.849 0.0157  0.000545 0.984 0.999
## # ... with 390 more rows
</code></pre>

<h3 id="cost-benefit-information">Cost/Benefit Information</h3>

<p>The cost-benefit matrix is a business assessment of the cost and benefit for each of four potential outcomes. To create such matrix I will have to make a few assumptions about the <strong>expenses and advantages</strong> that an organisation should consider when carrying out <strong>an advertising-led procurement drive</strong>.</p>

<p>Let&rsquo;s assume that the <strong>cost of selling a term deposits</strong> is of <strong>£30 per customer</strong>. This would include the likes of performing the direct marketing activity (training the call centre reps, setting time aside for active calls, etc.) and incentives such as offering a discounts on another financial product or on boarding onto membership schemes offering benefits and perks. A banking organisation will incur in this type of cost in two cases: when they correctly predict that a customer will subscribe ( <strong>true positive</strong>, TP), and when they incorrectly predict that a customer will subscribe ( <strong>false positive</strong>, FP).</p>

<p>Let’s also assume that the <strong>revenue of selling a term deposits</strong> to an existing customer is of <strong>£80 per customer</strong>. The organisation will guarantee this revenue stream when the model predicts that a customer will subscribe and they actually do ( <strong>true positive</strong>, TP).</p>

<p>Finally, there’s the <strong>true negative</strong> (TN) scenario where we correctly predict that a customer won’t subscribe. In this case we won’t spend any money but won&rsquo;t earn any revenue.</p>

<p>Here’s a quick recap of the cost scenarios:</p>

<ul>
<li><p><strong>True Positive</strong> (TP) - predict will subscribe, and they actually do: COST: -£30; REV £80</p></li>

<li><p><strong>False Positive</strong> (FP) - predict will subscribe, when they actually wouldn’t: COST: -£30; REV £0</p></li>

<li><p><strong>True Negative</strong> (TN) - predict won&rsquo;t subscribe, and they actually don’t: COST: £0; REV £0</p></li>

<li><p><strong>False Negative</strong> (FN) - predict won&rsquo;t subscribe, but they actually do: COST: £0; REV £0</p></li>
</ul>

<p>I create a function to calculate the expected cost using the probability of a <em>positive case</em> (p1) and the cost/benefit associated with a <em>true positive</em> (cb_tp) and a <em>false positive</em> (cb_fp). No need to include the <em>true negative</em> or <em>false negative</em> here as they&rsquo;re both zero.</p>

<p>I&rsquo;m also including the <strong>expected_rates</strong> data frame created previously with the expected rates for each threshold (400 thresholds, ranging from 0 to 1).</p>

<pre><code class="language-r"># Function to calculate expected profit
expected_profit_func &lt;- function(p1, cb_tp, cb_fp) {
  
    tibble(
        p1    = p1,
        cb_tp = cb_tp,
        cb_fp = cb_fp
        ) %&gt;%
    
        # add expected rates
        mutate(expected_rates = list(expected_rates)) %&gt;%
        unnest() %&gt;%
    
        # calculate the expected profit
        mutate(
            expected_profit =   p1    * (tpr * cb_tp) + 
                             (1 - p1) * (fpr * cb_fp)
        ) %&gt;%
        select(threshold, expected_profit)
}
</code></pre>

<h3 id="multi-customer-optimization">Multi-Customer Optimization</h3>

<p>Now to understand how a multi customer dynamic would work, I&rsquo;m creating a hypothetical 10 customer group to test my function on. This is a simplified view in that I&rsquo;m applying the same structure to all customers but the cost/benefit framework can be tailored to the individual customer to reflect their separate product and service level set up and the process can be easily adapted to optimise towards different KPIs (like net profit, CLV, acquisitions, etc.)</p>

<pre><code class="language-r"># Ten Hypothetical Customers 
ten_cust &lt;- tribble(
    ~&quot;cust&quot;,   ~&quot;p1&quot;,  ~&quot;cb_tp&quot;,  ~&quot;cb_fp&quot;,
    'ID1001',   0.1,    80 - 30,     -30,
    'ID1002',   0.2,    80 - 30,     -30,
    'ID1003',   0.3,    80 - 30,     -30,
    'ID1004',   0.4,    80 - 30,     -30,
    'ID1005',   0.5,    80 - 30,     -30,
    'ID1006',   0.6,    80 - 30,     -30,
    'ID1007',   0.7,    80 - 30,     -30,
    'ID1008',   0.8,    80 - 30,     -30,
    'ID1009',   0.9,    80 - 30,     -30,
    'ID1010',   1.0,    80 - 30,     -30
)
</code></pre>

<p>I use <code>purrr</code> to map the <code>expected_profit_func()</code> to each customer, returning a data frame of expected cost per customer by threshold value. This operation creates a nester tibble, which I have to <code>unnest()</code> to expand the data frame to one level.</p>

<pre><code class="language-r"># calculate expected cost for each at each threshold
expected_profit_ten_cust &lt;- ten_cust %&gt;%
    # pmap to map expected_profit_func() to each item
    mutate(expected_profit = pmap(.l = list(p1, cb_tp, cb_fp), 
                                  .f = expected_profit_func)) %&gt;%
    unnest() %&gt;%
    select(cust, p1, threshold, expected_profit) 
</code></pre>

<p><img src="/img/2020-04-20-propensity-modelling-3-of-3-optimise-profit-with-the-expected-value-framework/unnamed-chunk-11-1.png" alt="" width="100%" height="100%"/></p>

<p>Then, I can visualize the expected cost curves for each customer.</p>

<pre><code class="language-r"># Visualising Expected Cost 
expected_profit_ten_cust %&gt;%
    ggplot(aes(threshold, expected_profit, 
               colour = factor(cust)), 
               group = cust) +
    geom_line(size = 1) +
    theme_minimal()  +
    tidyquant::scale_color_tq() +
    labs(title = &quot;Expected Profit Curves&quot;,
         colour = &quot;Customer No.&quot; ) +
    theme(plot.title = element_text(hjust = 0.5))
</code></pre>

<p><img src="/img/2020-04-20-propensity-modelling-3-of-3-optimise-profit-with-the-expected-value-framework/unnamed-chunk-12-1.png" alt="" width="100%" height="100%"/></p>

<p>Finally, I can aggregate the expected cost, visualise the final curve and highlight the optimal threshold.</p>

<pre><code class="language-r"># Aggregate expected cost by threshold 
total_expected_profit_ten_cust &lt;- expected_profit_ten_cust %&gt;%
    group_by(threshold) %&gt;%
    summarise(expected_profit_total = sum(expected_profit)) 

# Get maximum optimal threshold 
max_expected_profit &lt;- total_expected_profit_ten_cust %&gt;%
    filter(expected_profit_total == max(expected_profit_total))

# Visualize the total expected profit curve
total_expected_profit_ten_cust %&gt;%
    ggplot(aes(threshold, expected_profit_total)) +
    geom_line(size = 1) +
    geom_vline(xintercept = max_expected_profit$threshold) +
    theme_minimal() +
    labs(title = &quot;Expected Profit Curve - Total Expected Profit&quot;,
         caption  = paste0('threshold @ max = ', 
                          max_expected_profit$threshold %&gt;% round(3))) +
    theme(plot.title = element_text(hjust = 0.5))
</code></pre>

<p>This has <strong>some important business implications</strong>. Based on our hypothetical 10-customer group, choosing the optimised threshold of <code>0.092</code> would yield a total profit of nearly <strong>£164</strong> compared to the nearly <strong>£147</strong> associated with the automatically selected cut-off of <code>0.190</code>.</p>

<p>This would result in an additional expected profit of <strong>nearly £1.7 per customer</strong>. Assuming that we have a customer base of approximately <strong>500,000</strong>, switching to the optimised model could generate an additional <strong>expected profit of £850k</strong>!</p>

<pre><code class="language-r">total_expected_profit_ten_cust %&gt;% 
  slice(184, 121) %&gt;%
  round(3) %&gt;%
  mutate(diff = expected_profit_total - lag(expected_profit_total))

## # A tibble: 2 x 3
##   threshold expected_profit_total  diff
##       &lt;dbl&gt;                 &lt;dbl&gt; &lt;dbl&gt;
## 1     0.19                   147.  NA  
## 2     0.092                  164.  16.9
</code></pre>

<p>It is easy to see that, depending on the size of your business, the magnitude of potential profit increase could be a significant.</p>

<h2 id="closing-thoughts">Closing thoughts</h2>

<p>In this final piece of the puzzle, I&rsquo;ve taken my <strong>final random forest</strong> model and implemented a <strong>multi-customer profit optimization</strong> that revealed a potential additional expected profit of <strong>nearly £1.7 per customer</strong> (or <strong>£850k</strong> if you had a 500,000 customer base).</p>

<p>Furthermore, I&rsquo;ve introduced key concepts like the <strong>threshold and F1 score</strong> and the <strong>precision-recall tradeoff</strong> and explained why it&rsquo;s highly important to decide which cutoff to call YES.</p>

<p>After exploring, cleansing and formatting the data, fitting and comparing multiple models and choosing the best one, sticking with the default threshold @ Max F1 would be stopping short of the ultimate &ldquo;so what?&rdquo; that puts all that hard work into prospective.</p>

<p>One final thing: don’t forget to shut-down the h2o instance when you’re done!</p>

<pre><code class="language-r">h2o.shutdown(prompt = FALSE)
</code></pre>

<h3 id="code-repository">Code Repository</h3>

<p>The full R code and all relevant files can be found on my GitHub profile @ <a href="https://github.com/DiegoUsaiUK/Propensity_Modelling"><strong>Propensity Modelling</strong></a></p>

<h3 id="references">References</h3>

<ul>
<li><p>For the original paper that used the data set see: <a href="http://repositorium.sdum.uminho.pt/bitstream/1822/30994/1/dss-v3.pdf"><strong>A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems</strong></a>, S. Moro, P. Cortez and P. Rita.</p></li>

<li><p>For an advanced tutorial on sales forecasting and product backorders optimisation see Matt Dancho&rsquo;s <a href="https://www.business-science.io/business/2017/10/16/sales_backorder_prediction.html"><strong>Predictive Sales Analytics: Use Machine Learning to Predict and Optimize Product Backorders</strong></a></p></li>

<li><p>For the <strong>Expected Value Framework</strong> see: <a href="https://www.goodreads.com/book/show/17912916-data-science-for-business"><em>Data Science for Business</em></a></p></li>
</ul>
    
        </div>
    </section>

    <footer class="post-full-footer">
      <section class="author-card">
        <img class="author-profile-image" src="/img/Me_1.jpg" alt="Author" />
        <section class="author-card-content">
            <h4 class="author-card-name"><a href="/">Diego Usai</a></h4>
                <p></p>
        </section>
      </section>
    </footer>
</article>
    
    
    

  </div>
</main>


<aside class="read-next outer">
  <div class="inner">
    <div class="read-next-feed">      
      
<article class="read-next-card" 
            style="background-image: url(/img/simon-zhu-TfRHSL2GKDc-unsplash.jpg);" >
    <header class="read-next-card-header">
        <small class="read-next-card-header-sitetitle">&mdash; Lifelong Learning &mdash;</small>
        
        <h3 class="read-next-card-header-title"><a href="/tags/propensity-modelling/">#Propensity Modelling</a></h3>
    </header>
    <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
    </div>

    <div class="read-next-card-content">
      
        <ul>
          <li><a href="/2019/06/modelling-with-tidymodels-and-parsnip/">Modelling with Tidymodels and Parsnip - A Tidy Approach to a Classification Problem</a></li>            
        
          <li><a href="/2019/03/market-basket-analysis-part-1-of-3/">Market Basket Analysis - Part 1 of 3 - Data Preparation and Exploratory Data Analysis</a></li>            
        
          <li><a href="/2019/10/build-your-website-with-hugo-and-blogdown/">Build Your Website with Hugo and blogdown - How I used RStudio, GitHub and Netlify to create and deploy my own webpage</a></li>            
        
          <li><a href="/2019/09/loading-merging-and-joining-datasets/">Loading, Merging and Joining Datasets</a></li>            
        </ul>
    </div>
    <footer class="read-next-card-footer">
      
        <a href="/tags/propensity-modelling/">See all related posts →</a>
    </footer>
</article>


      
      
      <article class="post-card post"> 
    
    <a class="post-card-image-link" href="/2020/03/propensity-modelling-2-of-3/">
      <div class="post-card-image" style="background-image: url(/img/bruna-branco-7r1HxvVC7AY-unsplash.jpg)"></div>
    </a>
    

    <div class="post-card-content">
      <a class="post-card-content-link" href="/2020/03/propensity-modelling-2-of-3/">
          <header class="post-card-header">
              <span class="post-card-tags">
              #Machine Learning 
              #Propensity Modelling 
              #ML Interpretability 
              #Model Selection  </span>
              
              <h2 class="post-card-title">Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 2 of 3 - Estimate Several Models and Compare Their Performance Using a Model-agnostic Methodology</h2>
          </header>
          <section class="post-card-excerpt">
              
                <p>In this day and age, a business that leverages data to understand the drivers of its customers&rsquo; behaviour has a true competitive advantage. Organisations can dramatically improve their performance in the market by analysing customer level data in an effective way and focus their efforts towards those that are more likely to engage.
One trialled and tested approach to tease out this type of insight is Propensity Modelling, which combines information such as a customers’ demographics (age, race, religion, gender, family size, ethnicity, income, education level), psycho-graphic (social class, lifestyle and personality characteristics), engagement (emails opened, emails clicked, searches on mobile app, webpage dwell time, etc. ...  </p>
              
          </section>
      </a>

      <footer class="post-card-meta">
          <img class="author-profile-image" src="/img/Me_1.jpg" alt="Author" />
          <span class="post-card-author"><a href="/">Diego Usai</a></span>
      </footer>
    </div>
</article>
      
    </div>
  </div>
</aside>

<div class="floating-header">
  <div class="floating-header-logo">
    <a href="/">
      
      <span></span>
    </a>
  </div>
  <span class="floating-header-divider">&mdash;</span>
  <div class="floating-header-title">Propensity Modelling - Using h2o and DALEX to Estimate the Likelihood of Purchasing a Financial Product - Part 3 of 3 - Optimise Profit With the Expected Value Framework</div>
  <div class="floating-header-share">
    <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
     <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/></svg>
    </div>
    
    <a class="floating-header-share-tw" href="https://twitter.com/share?text=Propensity%20Modelling%20-%20Using%20h2o%20and%20DALEX%20to%20Estimate%20the%20Likelihood%20of%20Purchasing%20a%20Financial%20Product%20-%20Part%203%20of%203%20-%20Optimise%20Profit%20With%20the%20Expected%20Value%20Framework&amp;url=%2f2020%2f04%2fpropensity-modelling-3-of-3%2f"
          onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
      </a>
      <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=%2f2020%2f04%2fpropensity-modelling-3-of-3%2f"
          onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
      </a>
  </div>

  <progress class="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>
</div>



<footer class="site-footer outer">
  <div class="site-footer-content inner">
    <section class="copyright" style="line-height: 1.3em;">
      <a href="/">Diego Usai</a> © 2019 <br>
      <span style="font-size: 0.8em; color: #555;">Hugo port of <a href="https://github.com/TryGhost/Casper">Casper 2.1.7</a> by <a href="https://www.telematika.org">EM</a></span>
    </section>
    <nav class="site-footer-nav">
        <a href="/">Latest Posts</a>
        
        
        <a href="https://github.com/DiegoUsaiUK" target="_blank" rel="noopener">Github</a>
        <a href="https://www.linkedin.com/in/diegousaiuk" target="_blank" rel="noopener">LinkedIn</a>
        <a href="https://medium.com/@diegousaiuk" target="_blank" rel="noopener">Medium</a>
    </nav>  
  </div>
</footer>

</div>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script type="text/javascript" src="//code.jquery.com/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="/js/jquery.fitvids.js"></script>

<script>hljs.initHighlightingOnLoad();</script>


  <!-- Google Analytics -->
  <script>
    var _gaq=[['_setAccount','UA-151122416-1'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>


    <script>





$(document).ready(function () {
    
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>
</body></html>
